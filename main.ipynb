{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7752f2d9-4140-43fd-b9fa-3bc2d9698c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"3\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import zipfile \n",
    "import io \n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    page_url='https://archive.ics.uci.edu/dataset/240/human+activity+recognition+using+smartphones'\n",
    "    response=requests.get(page_url)\n",
    "    if(response.status_code==200):\n",
    "        soup=BeautifulSoup(response.content,'html.parser')\n",
    "        link=soup.select_one('a[href$=\".zip\"]')['href']\n",
    "        download_url='https://archive.ics.uci.edu'+link\n",
    "        response_url=requests.get(download_url)\n",
    "        if(response_url.status_code==200):\n",
    "            with zipfile.ZipFile(io.BytesIO(response_url.content)) as outer_zip:\n",
    "                inner_zip_name= 'UCI HAR Dataset.zip'\n",
    "                with outer_zip.open(inner_zip_name) as inner_zip_file:\n",
    "                    with zipfile.ZipFile(io.BytesIO(inner_zip_file.read())) as inner_zip:\n",
    "                        with inner_zip.open('UCI HAR Dataset/train/X_train.txt') as myfile:\n",
    "                            df=pd.read_csv(myfile,delim_whitespace=True,header=None)\n",
    "                        with inner_zip.open('UCI HAR Dataset/train/y_train.txt') as myfile_y:\n",
    "                            y=pd.read_csv(myfile_y,delim_whitespace=True, header=None)\n",
    "        else:\n",
    "            raise Exception(\"falied to download the file or parse the dataset.\")\n",
    "        return df,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "903db686-07dd-456b-b6cb-cc144cdc0f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIT\\AppData\\Local\\Temp\\ipykernel_13232\\843175436.py:34: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df=pd.read_csv(myfile,delim_whitespace=True,header=None)\n",
      "C:\\Users\\BIT\\AppData\\Local\\Temp\\ipykernel_13232\\843175436.py:36: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  y=pd.read_csv(myfile_y,delim_whitespace=True, header=None)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"3\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "#loading datasets \n",
    "df,y=load_data()\n",
    "\n",
    "#Encode class labels\n",
    "label_encoder=LabelEncoder()\n",
    "encoded_y=label_encoder.fit_transform(y.values.ravel())\n",
    "\n",
    "#Scale the features\n",
    "scaler=StandardScaler()\n",
    "df_scaled=scaler.fit_transform(df)\n",
    "\n",
    "#Spit the data into training and testing sets for all the features\n",
    "X_train_full, X_test_full, y_train, y_test=train_test_split(df_scaled,encoded_y,test_size=0.2, random_state=42)\n",
    "\n",
    "import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#NaiveBayes\n",
    "start_time=time.time()\n",
    "classifier_pipeline_full=Pipeline([\n",
    "    ('classifier',GaussianNB())\n",
    "                           ])\n",
    "classifier_pipeline_full.fit(X_train_full,y_train)\n",
    "y_full=classifier_pipeline_full.predict(X_test_full)\n",
    "end_time=time.time()\n",
    "full_time=end_time-start_time\n",
    "accuracy=accuracy_score(y_test,y_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd6468c1-9dbe-4257-a910-63ae32c5de57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIT\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"3\"\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "# K-Means for Dimensionality-Reduction\n",
    "n_clusters=50\n",
    "kmeans=KMeans(n_clusters=n_clusters,random_state=42,n_init=10)\n",
    "kmeans.fit(df_scaled.T)\n",
    "selected_features_indices=[np.random.choice(np.where(kmeans.labels_ ==i)[0]) for i in range(n_clusters)]\n",
    "selected_features=df_scaled[:,selected_features_indices]\n",
    "\n",
    "#Split the data with reduces features\n",
    "X_train_reduced, X_test_reduced = train_test_split(selected_features, test_size=0.2 , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6482b10-73fd-4121-bed3-b6ddca9b453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"3\"\n",
    "\n",
    "import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#Model woth reduced features using Naive Byes\n",
    "start_time=time.time()\n",
    "classifier_pipeline_reduced=Pipeline([\n",
    "    ('classifier',GaussianNB())\n",
    "                        ])\n",
    "classifier_pipeline_reduced.fit(X_train_reduced, y_train)\n",
    "y_reduce= classifier_pipeline_reduced.predict(X_test_reduced)\n",
    "end_time=time.time()\n",
    "reduce_time=end_time-start_time\n",
    "accuracy_now= accuracy_score(y_test,y_reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67d31c80-ed3e-423a-b2c9-dc3d1846597b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model (All Features):\n",
      "Accuracy: 0.7314751869476547\n",
      "Training Time: 0.16648364067077637 seconds\n",
      "Number of Features: 561\n",
      "\n",
      "Model with Reduced Features (K-Means):\n",
      "Accuracy: 0.8348062542488104\n",
      "Training Time: 0.015496969223022461 seconds\n",
      "Number of Features: 50\n"
     ]
    }
   ],
   "source": [
    "# Print comparison results\n",
    "print(\"Baseline Model (All Features):\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Training Time:\", full_time, \"seconds\")\n",
    "print(\"Number of Features:\", X_train_full.shape[1])\n",
    "\n",
    "print(\"\\nModel with Reduced Features (K-Means):\")\n",
    "print(\"Accuracy:\", accuracy_now)\n",
    "print(\"Training Time:\", reduce_time, \"seconds\")\n",
    "print(\"Number of Features:\", n_clusters)\n",
    "\n",
    "\n",
    "#Final Result with Baseline Model and Model with Reduced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f165df21-3df3-46b8-8bdb-fca3c3d38ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
